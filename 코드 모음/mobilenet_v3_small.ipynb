{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c766c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bdb9b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir='C:\\\\Users\\\\SDH-LAB\\\\Desktop\\\\SMARCLE_MAKERS_DAY\\\\train_data'\n",
    "test_dir='C:\\\\Users\\\\SDH-LAB\\\\Desktop\\\\SMARCLE_MAKERS_DAY\\\\test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3ccbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e14f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagenerator = ImageDataGenerator(\n",
    "    horizontal_flip=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9288d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagenerator = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b9751da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagenerator = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60d3208d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18169 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagenerator.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b1fbb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blouse': 0, 'hoodie': 1, 't_shirt': 2}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11e0ca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 909 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = val_datagenerator.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ede61960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blouse': 0, 'hoodie': 1, 't_shirt': 2}\n"
     ]
    }
   ],
   "source": [
    "print(val_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d78a3ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 909 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagenerator.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba34780a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blouse': 0, 'hoodie': 1, 't_shirt': 2}\n"
     ]
    }
   ],
   "source": [
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f5331ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MobilenetV3small\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_1 (Rescaling)         (None, 224, 224, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv (Conv2D)                   (None, 112, 112, 16) 432         rescaling_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv/BatchNorm (BatchNormalizat (None, 112, 112, 16) 64          Conv[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_28 (TFOpLa (None, 112, 112, 16) 0           Conv/BatchNorm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, 112, 112, 16) 0           tf.__operators__.add_28[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_28 (TFOpLambda (None, 112, 112, 16) 0           re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 112, 112, 16) 0           tf.math.multiply_28[0][0]        \n",
      "                                                                 Conv/BatchNorm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/depthwise/pad (Ze (None, 113, 113, 16) 0           multiply_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/depthwise (Depthw (None, 56, 56, 16)   144         expanded_conv/depthwise/pad[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/depthwise/BatchNo (None, 56, 56, 16)   64          expanded_conv/depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_34 (ReLU)                 (None, 56, 56, 16)   0           expanded_conv/depthwise/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/squeeze_excite/Av (None, 16)           0           re_lu_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 1, 1, 16)     0           expanded_conv/squeeze_excite/AvgP\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/squeeze_excite/Co (None, 1, 1, 8)      136         reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/squeeze_excite/Re (None, 1, 1, 8)      0           expanded_conv/squeeze_excite/Conv\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/squeeze_excite/Co (None, 1, 1, 16)     144         expanded_conv/squeeze_excite/Relu\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_29 (TFOpLa (None, 1, 1, 16)     0           expanded_conv/squeeze_excite/Conv\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_35 (ReLU)                 (None, 1, 1, 16)     0           tf.__operators__.add_29[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_29 (TFOpLambda (None, 1, 1, 16)     0           re_lu_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/squeeze_excite/Mu (None, 56, 56, 16)   0           re_lu_34[0][0]                   \n",
      "                                                                 tf.math.multiply_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/project (Conv2D)  (None, 56, 56, 16)   256         expanded_conv/squeeze_excite/Mul[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/project/BatchNorm (None, 56, 56, 16)   64          expanded_conv/project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_1/expand (Conv2D) (None, 56, 56, 72)   1152        expanded_conv/project/BatchNorm[0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_1/expand/BatchNor (None, 56, 56, 72)   288         expanded_conv_1/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_36 (ReLU)                 (None, 56, 56, 72)   0           expanded_conv_1/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_1/depthwise/pad ( (None, 57, 57, 72)   0           re_lu_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_1/depthwise (Dept (None, 28, 28, 72)   648         expanded_conv_1/depthwise/pad[0][\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_1/depthwise/Batch (None, 28, 28, 72)   288         expanded_conv_1/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_37 (ReLU)                 (None, 28, 28, 72)   0           expanded_conv_1/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_1/project (Conv2D (None, 28, 28, 24)   1728        re_lu_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_1/project/BatchNo (None, 28, 28, 24)   96          expanded_conv_1/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_2/expand (Conv2D) (None, 28, 28, 88)   2112        expanded_conv_1/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_2/expand/BatchNor (None, 28, 28, 88)   352         expanded_conv_2/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_38 (ReLU)                 (None, 28, 28, 88)   0           expanded_conv_2/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_2/depthwise (Dept (None, 28, 28, 88)   792         re_lu_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_2/depthwise/Batch (None, 28, 28, 88)   352         expanded_conv_2/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_39 (ReLU)                 (None, 28, 28, 88)   0           expanded_conv_2/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_2/project (Conv2D (None, 28, 28, 24)   2112        re_lu_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_2/project/BatchNo (None, 28, 28, 24)   96          expanded_conv_2/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_2/Add (Add)       (None, 28, 28, 24)   0           expanded_conv_1/project/BatchNorm\n",
      "                                                                 expanded_conv_2/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/expand (Conv2D) (None, 28, 28, 96)   2304        expanded_conv_2/Add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/expand/BatchNor (None, 28, 28, 96)   384         expanded_conv_3/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_30 (TFOpLa (None, 28, 28, 96)   0           expanded_conv_3/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_40 (ReLU)                 (None, 28, 28, 96)   0           tf.__operators__.add_30[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_30 (TFOpLambda (None, 28, 28, 96)   0           re_lu_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 28, 28, 96)   0           tf.math.multiply_30[0][0]        \n",
      "                                                                 expanded_conv_3/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/depthwise/pad ( (None, 31, 31, 96)   0           multiply_20[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/depthwise (Dept (None, 14, 14, 96)   2400        expanded_conv_3/depthwise/pad[0][\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/depthwise/Batch (None, 14, 14, 96)   384         expanded_conv_3/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_31 (TFOpLa (None, 14, 14, 96)   0           expanded_conv_3/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_41 (ReLU)                 (None, 14, 14, 96)   0           tf.__operators__.add_31[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_31 (TFOpLambda (None, 14, 14, 96)   0           re_lu_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_21 (Multiply)          (None, 14, 14, 96)   0           tf.math.multiply_31[0][0]        \n",
      "                                                                 expanded_conv_3/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/squeeze_excite/ (None, 96)           0           multiply_21[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1, 1, 96)     0           expanded_conv_3/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/squeeze_excite/ (None, 1, 1, 24)     2328        reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/squeeze_excite/ (None, 1, 1, 24)     0           expanded_conv_3/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/squeeze_excite/ (None, 1, 1, 96)     2400        expanded_conv_3/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_32 (TFOpLa (None, 1, 1, 96)     0           expanded_conv_3/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_42 (ReLU)                 (None, 1, 1, 96)     0           tf.__operators__.add_32[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_32 (TFOpLambda (None, 1, 1, 96)     0           re_lu_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/squeeze_excite/ (None, 14, 14, 96)   0           multiply_21[0][0]                \n",
      "                                                                 tf.math.multiply_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/project (Conv2D (None, 14, 14, 40)   3840        expanded_conv_3/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/project/BatchNo (None, 14, 14, 40)   160         expanded_conv_3/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/expand (Conv2D) (None, 14, 14, 240)  9600        expanded_conv_3/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/expand/BatchNor (None, 14, 14, 240)  960         expanded_conv_4/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_33 (TFOpLa (None, 14, 14, 240)  0           expanded_conv_4/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_43 (ReLU)                 (None, 14, 14, 240)  0           tf.__operators__.add_33[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_33 (TFOpLambda (None, 14, 14, 240)  0           re_lu_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_22 (Multiply)          (None, 14, 14, 240)  0           tf.math.multiply_33[0][0]        \n",
      "                                                                 expanded_conv_4/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/depthwise (Dept (None, 14, 14, 240)  6000        multiply_22[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/depthwise/Batch (None, 14, 14, 240)  960         expanded_conv_4/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_34 (TFOpLa (None, 14, 14, 240)  0           expanded_conv_4/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_44 (ReLU)                 (None, 14, 14, 240)  0           tf.__operators__.add_34[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_34 (TFOpLambda (None, 14, 14, 240)  0           re_lu_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_23 (Multiply)          (None, 14, 14, 240)  0           tf.math.multiply_34[0][0]        \n",
      "                                                                 expanded_conv_4/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/squeeze_excite/ (None, 240)          0           multiply_23[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 1, 1, 240)    0           expanded_conv_4/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/squeeze_excite/ (None, 1, 1, 64)     15424       reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/squeeze_excite/ (None, 1, 1, 64)     0           expanded_conv_4/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/squeeze_excite/ (None, 1, 1, 240)    15600       expanded_conv_4/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_35 (TFOpLa (None, 1, 1, 240)    0           expanded_conv_4/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_45 (ReLU)                 (None, 1, 1, 240)    0           tf.__operators__.add_35[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_35 (TFOpLambda (None, 1, 1, 240)    0           re_lu_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/squeeze_excite/ (None, 14, 14, 240)  0           multiply_23[0][0]                \n",
      "                                                                 tf.math.multiply_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/project (Conv2D (None, 14, 14, 40)   9600        expanded_conv_4/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/project/BatchNo (None, 14, 14, 40)   160         expanded_conv_4/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/Add (Add)       (None, 14, 14, 40)   0           expanded_conv_3/project/BatchNorm\n",
      "                                                                 expanded_conv_4/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/expand (Conv2D) (None, 14, 14, 240)  9600        expanded_conv_4/Add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/expand/BatchNor (None, 14, 14, 240)  960         expanded_conv_5/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_36 (TFOpLa (None, 14, 14, 240)  0           expanded_conv_5/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_46 (ReLU)                 (None, 14, 14, 240)  0           tf.__operators__.add_36[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_36 (TFOpLambda (None, 14, 14, 240)  0           re_lu_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 14, 14, 240)  0           tf.math.multiply_36[0][0]        \n",
      "                                                                 expanded_conv_5/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/depthwise (Dept (None, 14, 14, 240)  6000        multiply_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/depthwise/Batch (None, 14, 14, 240)  960         expanded_conv_5/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_37 (TFOpLa (None, 14, 14, 240)  0           expanded_conv_5/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_47 (ReLU)                 (None, 14, 14, 240)  0           tf.__operators__.add_37[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_37 (TFOpLambda (None, 14, 14, 240)  0           re_lu_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 14, 14, 240)  0           tf.math.multiply_37[0][0]        \n",
      "                                                                 expanded_conv_5/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/squeeze_excite/ (None, 240)          0           multiply_25[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 1, 1, 240)    0           expanded_conv_5/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/squeeze_excite/ (None, 1, 1, 64)     15424       reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/squeeze_excite/ (None, 1, 1, 64)     0           expanded_conv_5/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/squeeze_excite/ (None, 1, 1, 240)    15600       expanded_conv_5/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_38 (TFOpLa (None, 1, 1, 240)    0           expanded_conv_5/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_48 (ReLU)                 (None, 1, 1, 240)    0           tf.__operators__.add_38[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_38 (TFOpLambda (None, 1, 1, 240)    0           re_lu_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/squeeze_excite/ (None, 14, 14, 240)  0           multiply_25[0][0]                \n",
      "                                                                 tf.math.multiply_38[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/project (Conv2D (None, 14, 14, 40)   9600        expanded_conv_5/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/project/BatchNo (None, 14, 14, 40)   160         expanded_conv_5/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/Add (Add)       (None, 14, 14, 40)   0           expanded_conv_4/Add[0][0]        \n",
      "                                                                 expanded_conv_5/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/expand (Conv2D) (None, 14, 14, 120)  4800        expanded_conv_5/Add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/expand/BatchNor (None, 14, 14, 120)  480         expanded_conv_6/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_39 (TFOpLa (None, 14, 14, 120)  0           expanded_conv_6/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_49 (ReLU)                 (None, 14, 14, 120)  0           tf.__operators__.add_39[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_39 (TFOpLambda (None, 14, 14, 120)  0           re_lu_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_26 (Multiply)          (None, 14, 14, 120)  0           tf.math.multiply_39[0][0]        \n",
      "                                                                 expanded_conv_6/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/depthwise (Dept (None, 14, 14, 120)  3000        multiply_26[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/depthwise/Batch (None, 14, 14, 120)  480         expanded_conv_6/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_40 (TFOpLa (None, 14, 14, 120)  0           expanded_conv_6/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_50 (ReLU)                 (None, 14, 14, 120)  0           tf.__operators__.add_40[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_40 (TFOpLambda (None, 14, 14, 120)  0           re_lu_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_27 (Multiply)          (None, 14, 14, 120)  0           tf.math.multiply_40[0][0]        \n",
      "                                                                 expanded_conv_6/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/squeeze_excite/ (None, 120)          0           multiply_27[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 1, 1, 120)    0           expanded_conv_6/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/squeeze_excite/ (None, 1, 1, 32)     3872        reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/squeeze_excite/ (None, 1, 1, 32)     0           expanded_conv_6/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/squeeze_excite/ (None, 1, 1, 120)    3960        expanded_conv_6/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_41 (TFOpLa (None, 1, 1, 120)    0           expanded_conv_6/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_51 (ReLU)                 (None, 1, 1, 120)    0           tf.__operators__.add_41[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_41 (TFOpLambda (None, 1, 1, 120)    0           re_lu_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/squeeze_excite/ (None, 14, 14, 120)  0           multiply_27[0][0]                \n",
      "                                                                 tf.math.multiply_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/project (Conv2D (None, 14, 14, 48)   5760        expanded_conv_6/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/project/BatchNo (None, 14, 14, 48)   192         expanded_conv_6/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/expand (Conv2D) (None, 14, 14, 144)  6912        expanded_conv_6/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/expand/BatchNor (None, 14, 14, 144)  576         expanded_conv_7/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_42 (TFOpLa (None, 14, 14, 144)  0           expanded_conv_7/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_52 (ReLU)                 (None, 14, 14, 144)  0           tf.__operators__.add_42[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_42 (TFOpLambda (None, 14, 14, 144)  0           re_lu_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_28 (Multiply)          (None, 14, 14, 144)  0           tf.math.multiply_42[0][0]        \n",
      "                                                                 expanded_conv_7/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/depthwise (Dept (None, 14, 14, 144)  3600        multiply_28[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/depthwise/Batch (None, 14, 14, 144)  576         expanded_conv_7/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_43 (TFOpLa (None, 14, 14, 144)  0           expanded_conv_7/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_53 (ReLU)                 (None, 14, 14, 144)  0           tf.__operators__.add_43[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_43 (TFOpLambda (None, 14, 14, 144)  0           re_lu_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_29 (Multiply)          (None, 14, 14, 144)  0           tf.math.multiply_43[0][0]        \n",
      "                                                                 expanded_conv_7/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/squeeze_excite/ (None, 144)          0           multiply_29[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 1, 1, 144)    0           expanded_conv_7/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/squeeze_excite/ (None, 1, 1, 40)     5800        reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/squeeze_excite/ (None, 1, 1, 40)     0           expanded_conv_7/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/squeeze_excite/ (None, 1, 1, 144)    5904        expanded_conv_7/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_44 (TFOpLa (None, 1, 1, 144)    0           expanded_conv_7/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_54 (ReLU)                 (None, 1, 1, 144)    0           tf.__operators__.add_44[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_44 (TFOpLambda (None, 1, 1, 144)    0           re_lu_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/squeeze_excite/ (None, 14, 14, 144)  0           multiply_29[0][0]                \n",
      "                                                                 tf.math.multiply_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/project (Conv2D (None, 14, 14, 48)   6912        expanded_conv_7/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/project/BatchNo (None, 14, 14, 48)   192         expanded_conv_7/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/Add (Add)       (None, 14, 14, 48)   0           expanded_conv_6/project/BatchNorm\n",
      "                                                                 expanded_conv_7/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/expand (Conv2D) (None, 14, 14, 288)  13824       expanded_conv_7/Add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/expand/BatchNor (None, 14, 14, 288)  1152        expanded_conv_8/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_45 (TFOpLa (None, 14, 14, 288)  0           expanded_conv_8/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_55 (ReLU)                 (None, 14, 14, 288)  0           tf.__operators__.add_45[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_45 (TFOpLambda (None, 14, 14, 288)  0           re_lu_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_30 (Multiply)          (None, 14, 14, 288)  0           tf.math.multiply_45[0][0]        \n",
      "                                                                 expanded_conv_8/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/depthwise/pad ( (None, 17, 17, 288)  0           multiply_30[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/depthwise (Dept (None, 7, 7, 288)    7200        expanded_conv_8/depthwise/pad[0][\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/depthwise/Batch (None, 7, 7, 288)    1152        expanded_conv_8/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_46 (TFOpLa (None, 7, 7, 288)    0           expanded_conv_8/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_56 (ReLU)                 (None, 7, 7, 288)    0           tf.__operators__.add_46[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_46 (TFOpLambda (None, 7, 7, 288)    0           re_lu_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_31 (Multiply)          (None, 7, 7, 288)    0           tf.math.multiply_46[0][0]        \n",
      "                                                                 expanded_conv_8/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/squeeze_excite/ (None, 288)          0           multiply_31[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 1, 1, 288)    0           expanded_conv_8/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/squeeze_excite/ (None, 1, 1, 72)     20808       reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/squeeze_excite/ (None, 1, 1, 72)     0           expanded_conv_8/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/squeeze_excite/ (None, 1, 1, 288)    21024       expanded_conv_8/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_47 (TFOpLa (None, 1, 1, 288)    0           expanded_conv_8/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_57 (ReLU)                 (None, 1, 1, 288)    0           tf.__operators__.add_47[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_47 (TFOpLambda (None, 1, 1, 288)    0           re_lu_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/squeeze_excite/ (None, 7, 7, 288)    0           multiply_31[0][0]                \n",
      "                                                                 tf.math.multiply_47[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/project (Conv2D (None, 7, 7, 96)     27648       expanded_conv_8/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/project/BatchNo (None, 7, 7, 96)     384         expanded_conv_8/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/expand (Conv2D) (None, 7, 7, 576)    55296       expanded_conv_8/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/expand/BatchNor (None, 7, 7, 576)    2304        expanded_conv_9/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_48 (TFOpLa (None, 7, 7, 576)    0           expanded_conv_9/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_58 (ReLU)                 (None, 7, 7, 576)    0           tf.__operators__.add_48[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_48 (TFOpLambda (None, 7, 7, 576)    0           re_lu_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 7, 7, 576)    0           tf.math.multiply_48[0][0]        \n",
      "                                                                 expanded_conv_9/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/depthwise (Dept (None, 7, 7, 576)    14400       multiply_32[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/depthwise/Batch (None, 7, 7, 576)    2304        expanded_conv_9/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_49 (TFOpLa (None, 7, 7, 576)    0           expanded_conv_9/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_59 (ReLU)                 (None, 7, 7, 576)    0           tf.__operators__.add_49[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_49 (TFOpLambda (None, 7, 7, 576)    0           re_lu_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 7, 7, 576)    0           tf.math.multiply_49[0][0]        \n",
      "                                                                 expanded_conv_9/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/squeeze_excite/ (None, 576)          0           multiply_33[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 1, 1, 576)    0           expanded_conv_9/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/squeeze_excite/ (None, 1, 1, 144)    83088       reshape_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/squeeze_excite/ (None, 1, 1, 144)    0           expanded_conv_9/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/squeeze_excite/ (None, 1, 1, 576)    83520       expanded_conv_9/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_50 (TFOpLa (None, 1, 1, 576)    0           expanded_conv_9/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_60 (ReLU)                 (None, 1, 1, 576)    0           tf.__operators__.add_50[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_50 (TFOpLambda (None, 1, 1, 576)    0           re_lu_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/squeeze_excite/ (None, 7, 7, 576)    0           multiply_33[0][0]                \n",
      "                                                                 tf.math.multiply_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/project (Conv2D (None, 7, 7, 96)     55296       expanded_conv_9/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/project/BatchNo (None, 7, 7, 96)     384         expanded_conv_9/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/Add (Add)       (None, 7, 7, 96)     0           expanded_conv_8/project/BatchNorm\n",
      "                                                                 expanded_conv_9/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/expand (Conv2D (None, 7, 7, 576)    55296       expanded_conv_9/Add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/expand/BatchNo (None, 7, 7, 576)    2304        expanded_conv_10/expand[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_51 (TFOpLa (None, 7, 7, 576)    0           expanded_conv_10/expand/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_61 (ReLU)                 (None, 7, 7, 576)    0           tf.__operators__.add_51[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_51 (TFOpLambda (None, 7, 7, 576)    0           re_lu_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 7, 7, 576)    0           tf.math.multiply_51[0][0]        \n",
      "                                                                 expanded_conv_10/expand/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/depthwise (Dep (None, 7, 7, 576)    14400       multiply_34[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/depthwise/Batc (None, 7, 7, 576)    2304        expanded_conv_10/depthwise[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_52 (TFOpLa (None, 7, 7, 576)    0           expanded_conv_10/depthwise/BatchN\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_62 (ReLU)                 (None, 7, 7, 576)    0           tf.__operators__.add_52[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_52 (TFOpLambda (None, 7, 7, 576)    0           re_lu_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 7, 7, 576)    0           tf.math.multiply_52[0][0]        \n",
      "                                                                 expanded_conv_10/depthwise/BatchN\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/squeeze_excite (None, 576)          0           multiply_35[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 1, 1, 576)    0           expanded_conv_10/squeeze_excite/A\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/squeeze_excite (None, 1, 1, 144)    83088       reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/squeeze_excite (None, 1, 1, 144)    0           expanded_conv_10/squeeze_excite/C\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/squeeze_excite (None, 1, 1, 576)    83520       expanded_conv_10/squeeze_excite/R\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_53 (TFOpLa (None, 1, 1, 576)    0           expanded_conv_10/squeeze_excite/C\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_63 (ReLU)                 (None, 1, 1, 576)    0           tf.__operators__.add_53[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_53 (TFOpLambda (None, 1, 1, 576)    0           re_lu_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/squeeze_excite (None, 7, 7, 576)    0           multiply_35[0][0]                \n",
      "                                                                 tf.math.multiply_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/project (Conv2 (None, 7, 7, 96)     55296       expanded_conv_10/squeeze_excite/M\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/project/BatchN (None, 7, 7, 96)     384         expanded_conv_10/project[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/Add (Add)      (None, 7, 7, 96)     0           expanded_conv_9/Add[0][0]        \n",
      "                                                                 expanded_conv_10/project/BatchNor\n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 576)    55296       expanded_conv_10/Add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1/BatchNorm (BatchNormaliz (None, 7, 7, 576)    2304        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_54 (TFOpLa (None, 7, 7, 576)    0           Conv_1/BatchNorm[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_64 (ReLU)                 (None, 7, 7, 576)    0           tf.__operators__.add_54[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_54 (TFOpLambda (None, 7, 7, 576)    0           re_lu_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_36 (Multiply)          (None, 7, 7, 576)    0           tf.math.multiply_54[0][0]        \n",
      "                                                                 Conv_1/BatchNorm[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_2 (Conv2D)                 (None, 7, 7, 1024)   590848      multiply_36[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_55 (TFOpLa (None, 7, 7, 1024)   0           Conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_65 (ReLU)                 (None, 7, 7, 1024)   0           tf.__operators__.add_55[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_55 (TFOpLambda (None, 7, 7, 1024)   0           re_lu_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_37 (Multiply)          (None, 7, 7, 1024)   0           tf.math.multiply_55[0][0]        \n",
      "                                                                 Conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1024)         0           multiply_37[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,529,968\n",
      "Trainable params: 1,517,856\n",
      "Non-trainable params: 12,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV3Small(\n",
    "    input_shape=(224,224,3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "\n",
    "#summary\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "807a4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Dense(units=3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bd45dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "MobilenetV3small (Functional (None, 1024)              1529968   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 1,533,043\n",
      "Trainable params: 1,520,931\n",
      "Non-trainable params: 12,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a307471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=len(train_generator),\n",
    "          epochs=30\n",
    "          )\n",
    "'''\n",
    "print(\"_____________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59bb6517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "'''\n",
    "print(\"__________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e8bcf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "568/568 [==============================] - 72s 120ms/step - loss: 0.4633 - acc: 0.8240 - val_loss: 3.7031 - val_acc: 0.5886\n",
      "current decayed lr: 0.0007930\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.58856, saving model to .\\name_of_model.h5\n",
      "Epoch 2/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.1438 - acc: 0.9465 - val_loss: 2.4297 - val_acc: 0.6359\n",
      "current decayed lr: 0.0006289\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.58856 to 0.63586, saving model to .\\name_of_model.h5\n",
      "Epoch 3/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0764 - acc: 0.9712 - val_loss: 2.3286 - val_acc: 0.6238\n",
      "current decayed lr: 0.0004988\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.63586\n",
      "Epoch 4/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0550 - acc: 0.9796 - val_loss: 1.8546 - val_acc: 0.6876\n",
      "current decayed lr: 0.0003956\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.63586 to 0.68757, saving model to .\\name_of_model.h5\n",
      "Epoch 5/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0289 - acc: 0.9893 - val_loss: 1.8087 - val_acc: 0.7107\n",
      "current decayed lr: 0.0003137\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.68757 to 0.71067, saving model to .\\name_of_model.h5\n",
      "Epoch 6/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0205 - acc: 0.9932 - val_loss: 2.3784 - val_acc: 0.6667\n",
      "current decayed lr: 0.0002488\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.71067\n",
      "Epoch 7/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0164 - acc: 0.9951 - val_loss: 2.5676 - val_acc: 0.6623\n",
      "current decayed lr: 0.0001973\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.71067\n",
      "Epoch 8/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0103 - acc: 0.9969 - val_loss: 2.1602 - val_acc: 0.6865\n",
      "current decayed lr: 0.0001565\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.71067\n",
      "Epoch 9/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0071 - acc: 0.9974 - val_loss: 2.5930 - val_acc: 0.6821\n",
      "current decayed lr: 0.0001241\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.71067\n",
      "Epoch 10/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0051 - acc: 0.9980 - val_loss: 2.8468 - val_acc: 0.6634\n",
      "current decayed lr: 0.0000984\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.71067\n",
      "Epoch 11/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0044 - acc: 0.9986 - val_loss: 2.8240 - val_acc: 0.6755\n",
      "current decayed lr: 0.0000780\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.71067\n",
      "Epoch 12/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0051 - acc: 0.9974 - val_loss: 2.5101 - val_acc: 0.6865\n",
      "current decayed lr: 0.0000619\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.71067\n",
      "Epoch 13/250\n",
      "568/568 [==============================] - 67s 119ms/step - loss: 0.0040 - acc: 0.9983 - val_loss: 2.8838 - val_acc: 0.6755\n",
      "current decayed lr: 0.0000491\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.71067\n",
      "Epoch 14/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0033 - acc: 0.9985 - val_loss: 2.6302 - val_acc: 0.6953\n",
      "current decayed lr: 0.0000389\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.71067\n",
      "Epoch 15/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0028 - acc: 0.9987 - val_loss: 2.7864 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000309\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.71067\n",
      "Epoch 16/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9988 - val_loss: 2.7108 - val_acc: 0.6898\n",
      "current decayed lr: 0.0000245\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.71067\n",
      "Epoch 17/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0029 - acc: 0.9984 - val_loss: 2.7662 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000194\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.71067\n",
      "Epoch 18/250\n",
      "568/568 [==============================] - 67s 119ms/step - loss: 0.0029 - acc: 0.9985 - val_loss: 2.8624 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000154\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.71067\n",
      "Epoch 19/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0031 - acc: 0.9983 - val_loss: 2.7900 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000122\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.71067\n",
      "Epoch 20/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0025 - acc: 0.9986 - val_loss: 2.7476 - val_acc: 0.6942\n",
      "current decayed lr: 0.0000097\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.71067\n",
      "Epoch 21/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9988 - val_loss: 2.7374 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000077\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.71067\n",
      "Epoch 22/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9989 - val_loss: 2.7528 - val_acc: 0.6953\n",
      "current decayed lr: 0.0000061\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.71067\n",
      "Epoch 23/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0026 - acc: 0.9988 - val_loss: 2.7356 - val_acc: 0.6942\n",
      "current decayed lr: 0.0000048\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.71067\n",
      "Epoch 24/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0025 - acc: 0.9989 - val_loss: 2.7117 - val_acc: 0.6997\n",
      "current decayed lr: 0.0000038\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.71067\n",
      "Epoch 25/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0024 - acc: 0.9985 - val_loss: 2.7251 - val_acc: 0.6975\n",
      "current decayed lr: 0.0000030\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.71067\n",
      "Epoch 26/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9987 - val_loss: 2.7561 - val_acc: 0.6953\n",
      "current decayed lr: 0.0000024\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.71067\n",
      "Epoch 27/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0025 - acc: 0.9987 - val_loss: 2.7560 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000019\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.71067\n",
      "Epoch 28/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0025 - acc: 0.9986 - val_loss: 2.7595 - val_acc: 0.6898\n",
      "current decayed lr: 0.0000015\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.71067\n",
      "Epoch 29/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0024 - acc: 0.9983 - val_loss: 2.7860 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000012\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.71067\n",
      "Epoch 30/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0028 - acc: 0.9989 - val_loss: 2.7830 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000010\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.71067\n",
      "Epoch 31/250\n",
      "568/568 [==============================] - 67s 119ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 2.7832 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000008\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.71067\n",
      "Epoch 32/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0012 - acc: 0.9994 - val_loss: 2.7836 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000006\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.71067\n",
      "Epoch 33/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 2.7852 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000005\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.71067\n",
      "Epoch 34/250\n",
      "568/568 [==============================] - 67s 119ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 2.7926 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000004\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.71067\n",
      "Epoch 35/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9985 - val_loss: 2.7926 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000003\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.71067\n",
      "Epoch 36/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 2.7868 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000002\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.71067\n",
      "Epoch 37/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9986 - val_loss: 2.7878 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000002\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.71067\n",
      "Epoch 38/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9988 - val_loss: 2.7964 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000001\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.71067\n",
      "Epoch 39/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9990 - val_loss: 2.7968 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000001\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.71067\n",
      "Epoch 40/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0025 - acc: 0.9984 - val_loss: 2.7919 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000001\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.71067\n",
      "Epoch 41/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9989 - val_loss: 2.7915 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000001\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.71067\n",
      "Epoch 42/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9990 - val_loss: 2.7932 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000001\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.71067\n",
      "Epoch 43/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9990 - val_loss: 2.7919 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.71067\n",
      "Epoch 44/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9985 - val_loss: 2.7899 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.71067\n",
      "Epoch 45/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9988 - val_loss: 2.7890 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.71067\n",
      "Epoch 46/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0027 - acc: 0.9983 - val_loss: 2.7895 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.71067\n",
      "Epoch 47/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0015 - acc: 0.9994 - val_loss: 2.7950 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.71067\n",
      "Epoch 48/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0015 - acc: 0.9990 - val_loss: 2.7949 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.71067\n",
      "Epoch 49/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0026 - acc: 0.9987 - val_loss: 2.7940 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.71067\n",
      "Epoch 50/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0014 - acc: 0.9993 - val_loss: 2.7905 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.71067\n",
      "Epoch 51/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9988 - val_loss: 2.7911 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.71067\n",
      "Epoch 52/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0031 - acc: 0.9981 - val_loss: 2.7908 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.71067\n",
      "Epoch 53/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9988 - val_loss: 2.7910 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.71067\n",
      "Epoch 54/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9992 - val_loss: 2.7942 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.71067\n",
      "Epoch 55/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9991 - val_loss: 2.7912 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.71067\n",
      "Epoch 56/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0024 - acc: 0.9987 - val_loss: 2.7906 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.71067\n",
      "Epoch 57/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0024 - acc: 0.9981 - val_loss: 2.7890 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.71067\n",
      "Epoch 58/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9988 - val_loss: 2.7871 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.71067\n",
      "Epoch 59/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0024 - acc: 0.9983 - val_loss: 2.7892 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.71067\n",
      "Epoch 60/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9983 - val_loss: 2.7862 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.71067\n",
      "Epoch 61/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9987 - val_loss: 2.7901 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.71067\n",
      "Epoch 62/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9987 - val_loss: 2.7908 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.71067\n",
      "Epoch 63/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9990 - val_loss: 2.7906 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.71067\n",
      "Epoch 64/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9990 - val_loss: 2.7932 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.71067\n",
      "Epoch 65/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0016 - acc: 0.9993 - val_loss: 2.7925 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.71067\n",
      "Epoch 66/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0016 - acc: 0.9993 - val_loss: 2.7934 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.71067\n",
      "Epoch 67/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0024 - acc: 0.9984 - val_loss: 2.7918 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.71067\n",
      "Epoch 68/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9985 - val_loss: 2.7892 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.71067\n",
      "Epoch 69/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9991 - val_loss: 2.7918 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.71067\n",
      "Epoch 70/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0013 - acc: 0.9993 - val_loss: 2.7933 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.71067\n",
      "Epoch 71/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9992 - val_loss: 2.7943 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.71067\n",
      "Epoch 72/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0015 - acc: 0.9991 - val_loss: 2.7938 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.71067\n",
      "Epoch 73/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0026 - acc: 0.9984 - val_loss: 2.7944 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.71067\n",
      "Epoch 74/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0027 - acc: 0.9983 - val_loss: 2.7948 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.71067\n",
      "Epoch 75/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9988 - val_loss: 2.7928 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.71067\n",
      "Epoch 76/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0016 - acc: 0.9993 - val_loss: 2.7894 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.71067\n",
      "Epoch 77/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9989 - val_loss: 2.7899 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.71067\n",
      "Epoch 78/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9985 - val_loss: 2.7888 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.71067\n",
      "Epoch 79/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0025 - acc: 0.9984 - val_loss: 2.7897 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.71067\n",
      "Epoch 80/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0024 - acc: 0.9985 - val_loss: 2.7874 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.71067\n",
      "Epoch 81/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9986 - val_loss: 2.7907 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.71067\n",
      "Epoch 82/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9988 - val_loss: 2.7898 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.71067\n",
      "Epoch 83/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9992 - val_loss: 2.7891 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.71067\n",
      "Epoch 84/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9993 - val_loss: 2.7891 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.71067\n",
      "Epoch 85/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0016 - acc: 0.9989 - val_loss: 2.7851 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.71067\n",
      "Epoch 86/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9992 - val_loss: 2.7838 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.71067\n",
      "Epoch 87/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9993 - val_loss: 2.7881 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.71067\n",
      "Epoch 88/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0025 - acc: 0.9986 - val_loss: 2.7896 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.71067\n",
      "Epoch 89/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9987 - val_loss: 2.7834 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.71067\n",
      "Epoch 90/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9992 - val_loss: 2.7864 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.71067\n",
      "Epoch 91/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9990 - val_loss: 2.7877 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.71067\n",
      "Epoch 92/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9992 - val_loss: 2.7902 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.71067\n",
      "Epoch 93/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9986 - val_loss: 2.7944 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.71067\n",
      "Epoch 94/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9986 - val_loss: 2.7958 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.71067\n",
      "Epoch 95/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9990 - val_loss: 2.7937 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.71067\n",
      "Epoch 96/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0027 - acc: 0.9990 - val_loss: 2.7906 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.71067\n",
      "Epoch 97/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9983 - val_loss: 2.7922 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.71067\n",
      "Epoch 98/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9986 - val_loss: 2.7889 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.71067\n",
      "Epoch 99/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9982 - val_loss: 2.7929 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.71067\n",
      "Epoch 100/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0015 - acc: 0.9993 - val_loss: 2.7932 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.71067\n",
      "Epoch 101/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0024 - acc: 0.9985 - val_loss: 2.7914 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.71067\n",
      "Epoch 102/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9985 - val_loss: 2.7905 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.71067\n",
      "Epoch 103/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9990 - val_loss: 2.7927 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.71067\n",
      "Epoch 104/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9989 - val_loss: 2.7933 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.71067\n",
      "Epoch 105/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0026 - acc: 0.9984 - val_loss: 2.7899 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.71067\n",
      "Epoch 106/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9987 - val_loss: 2.7916 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.71067\n",
      "Epoch 107/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9987 - val_loss: 2.7940 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.71067\n",
      "Epoch 108/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9989 - val_loss: 2.7921 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.71067\n",
      "Epoch 109/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0016 - acc: 0.9993 - val_loss: 2.7924 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.71067\n",
      "Epoch 110/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0027 - acc: 0.9981 - val_loss: 2.7934 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.71067\n",
      "Epoch 111/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9989 - val_loss: 2.7947 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.71067\n",
      "Epoch 112/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9992 - val_loss: 2.7918 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.71067\n",
      "Epoch 113/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0016 - acc: 0.9993 - val_loss: 2.7912 - val_acc: 0.6909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.71067\n",
      "Epoch 114/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0013 - acc: 0.9995 - val_loss: 2.7897 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.71067\n",
      "Epoch 115/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9989 - val_loss: 2.7846 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.71067\n",
      "Epoch 116/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9991 - val_loss: 2.7901 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.71067\n",
      "Epoch 117/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9990 - val_loss: 2.7908 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.71067\n",
      "Epoch 118/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9990 - val_loss: 2.7950 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.71067\n",
      "Epoch 119/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9990 - val_loss: 2.7934 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.71067\n",
      "Epoch 120/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 2.7894 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.71067\n",
      "Epoch 121/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 2.7923 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.71067\n",
      "Epoch 122/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9989 - val_loss: 2.7884 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.71067\n",
      "Epoch 123/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0025 - acc: 0.9983 - val_loss: 2.7898 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.71067\n",
      "Epoch 124/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0014 - acc: 0.9994 - val_loss: 2.7878 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.71067\n",
      "Epoch 125/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9992 - val_loss: 2.7868 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.71067\n",
      "Epoch 126/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9983 - val_loss: 2.7895 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.71067\n",
      "Epoch 127/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0024 - acc: 0.9984 - val_loss: 2.7890 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.71067\n",
      "Epoch 128/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0025 - acc: 0.9983 - val_loss: 2.7900 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.71067\n",
      "Epoch 129/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9992 - val_loss: 2.7915 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.71067\n",
      "Epoch 130/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9986 - val_loss: 2.7917 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.71067\n",
      "Epoch 131/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9992 - val_loss: 2.7925 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.71067\n",
      "Epoch 132/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 2.7925 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.71067\n",
      "Epoch 133/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9987 - val_loss: 2.7890 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.71067\n",
      "Epoch 134/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0024 - acc: 0.9986 - val_loss: 2.7910 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.71067\n",
      "Epoch 135/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0015 - acc: 0.9994 - val_loss: 2.7915 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.71067\n",
      "Epoch 136/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9994 - val_loss: 2.7926 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.71067\n",
      "Epoch 137/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9987 - val_loss: 2.7920 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.71067\n",
      "Epoch 138/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9985 - val_loss: 2.7956 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.71067\n",
      "Epoch 139/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0026 - acc: 0.9988 - val_loss: 2.7941 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.71067\n",
      "Epoch 140/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9993 - val_loss: 2.7905 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.71067\n",
      "Epoch 141/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0026 - acc: 0.9987 - val_loss: 2.7907 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.71067\n",
      "Epoch 142/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9988 - val_loss: 2.7892 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.71067\n",
      "Epoch 143/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9987 - val_loss: 2.7903 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.71067\n",
      "Epoch 144/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9990 - val_loss: 2.7937 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.71067\n",
      "Epoch 145/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9988 - val_loss: 2.7933 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.71067\n",
      "Epoch 146/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9988 - val_loss: 2.7930 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.71067\n",
      "Epoch 147/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0024 - acc: 0.9985 - val_loss: 2.7903 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.71067\n",
      "Epoch 148/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9990 - val_loss: 2.7902 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.71067\n",
      "Epoch 149/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9985 - val_loss: 2.7910 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.71067\n",
      "Epoch 150/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 2.7892 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.71067\n",
      "Epoch 151/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9992 - val_loss: 2.7908 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.71067\n",
      "Epoch 152/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9986 - val_loss: 2.7913 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.71067\n",
      "Epoch 153/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 2.7898 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.71067\n",
      "Epoch 154/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9989 - val_loss: 2.7919 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.71067\n",
      "Epoch 155/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0026 - acc: 0.9989 - val_loss: 2.7917 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.71067\n",
      "Epoch 156/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9994 - val_loss: 2.7930 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.71067\n",
      "Epoch 157/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9994 - val_loss: 2.7952 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.71067\n",
      "Epoch 158/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0016 - acc: 0.9993 - val_loss: 2.7919 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.71067\n",
      "Epoch 159/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 2.7911 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.71067\n",
      "Epoch 160/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9989 - val_loss: 2.7923 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.71067\n",
      "Epoch 161/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0025 - acc: 0.9987 - val_loss: 2.7910 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.71067\n",
      "Epoch 162/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9986 - val_loss: 2.7946 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.71067\n",
      "Epoch 163/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0025 - acc: 0.9984 - val_loss: 2.7956 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.71067\n",
      "Epoch 164/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0015 - acc: 0.9991 - val_loss: 2.7918 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.71067\n",
      "Epoch 165/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9993 - val_loss: 2.7932 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.71067\n",
      "Epoch 166/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9987 - val_loss: 2.7932 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.71067\n",
      "Epoch 167/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0025 - acc: 0.9985 - val_loss: 2.7914 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.71067\n",
      "Epoch 168/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9990 - val_loss: 2.7872 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.71067\n",
      "Epoch 169/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9987 - val_loss: 2.7866 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.71067\n",
      "Epoch 170/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9992 - val_loss: 2.7901 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.71067\n",
      "Epoch 171/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9989 - val_loss: 2.7902 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.71067\n",
      "Epoch 172/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0025 - acc: 0.9987 - val_loss: 2.7882 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.71067\n",
      "Epoch 173/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 2.7894 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.71067\n",
      "Epoch 174/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9989 - val_loss: 2.7913 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.71067\n",
      "Epoch 175/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9994 - val_loss: 2.7916 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.71067\n",
      "Epoch 176/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0016 - acc: 0.9991 - val_loss: 2.7912 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.71067\n",
      "Epoch 177/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0027 - acc: 0.9986 - val_loss: 2.7923 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.71067\n",
      "Epoch 178/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9990 - val_loss: 2.7907 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.71067\n",
      "Epoch 179/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9990 - val_loss: 2.7901 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.71067\n",
      "Epoch 180/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9986 - val_loss: 2.7883 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.71067\n",
      "Epoch 181/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9984 - val_loss: 2.7872 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.71067\n",
      "Epoch 182/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9986 - val_loss: 2.7910 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.71067\n",
      "Epoch 183/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9986 - val_loss: 2.7928 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.71067\n",
      "Epoch 184/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9989 - val_loss: 2.7963 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.71067\n",
      "Epoch 185/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9990 - val_loss: 2.7931 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.71067\n",
      "Epoch 186/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 2.7916 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.71067\n",
      "Epoch 187/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0016 - acc: 0.9988 - val_loss: 2.7910 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.71067\n",
      "Epoch 188/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9987 - val_loss: 2.7902 - val_acc: 0.6909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.71067\n",
      "Epoch 189/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 2.7943 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.71067\n",
      "Epoch 190/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9987 - val_loss: 2.7911 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.71067\n",
      "Epoch 191/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0028 - acc: 0.9985 - val_loss: 2.7923 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.71067\n",
      "Epoch 192/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 2.7936 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.71067\n",
      "Epoch 193/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0024 - acc: 0.9987 - val_loss: 2.7929 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.71067\n",
      "Epoch 194/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9989 - val_loss: 2.7933 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.71067\n",
      "Epoch 195/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0025 - acc: 0.9987 - val_loss: 2.7914 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.71067\n",
      "Epoch 196/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9985 - val_loss: 2.7917 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.71067\n",
      "Epoch 197/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9992 - val_loss: 2.7930 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.71067\n",
      "Epoch 198/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9988 - val_loss: 2.7883 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.71067\n",
      "Epoch 199/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9987 - val_loss: 2.7897 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.71067\n",
      "Epoch 200/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9988 - val_loss: 2.7881 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.71067\n",
      "Epoch 201/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9991 - val_loss: 2.7868 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.71067\n",
      "Epoch 202/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9990 - val_loss: 2.7886 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.71067\n",
      "Epoch 203/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9986 - val_loss: 2.7886 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.71067\n",
      "Epoch 204/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9986 - val_loss: 2.7908 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.71067\n",
      "Epoch 205/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 2.7913 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.71067\n",
      "Epoch 206/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9989 - val_loss: 2.7897 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.71067\n",
      "Epoch 207/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9987 - val_loss: 2.7905 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.71067\n",
      "Epoch 208/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9990 - val_loss: 2.7946 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.71067\n",
      "Epoch 209/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9992 - val_loss: 2.7953 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.71067\n",
      "Epoch 210/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9985 - val_loss: 2.7919 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.71067\n",
      "Epoch 211/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9986 - val_loss: 2.7909 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.71067\n",
      "Epoch 212/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9988 - val_loss: 2.7937 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.71067\n",
      "Epoch 213/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9990 - val_loss: 2.7902 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.71067\n",
      "Epoch 214/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9988 - val_loss: 2.7887 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.71067\n",
      "Epoch 215/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9988 - val_loss: 2.7900 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.71067\n",
      "Epoch 216/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9989 - val_loss: 2.7913 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.71067\n",
      "Epoch 217/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9988 - val_loss: 2.7914 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.71067\n",
      "Epoch 218/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9986 - val_loss: 2.7897 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.71067\n",
      "Epoch 219/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0017 - acc: 0.9992 - val_loss: 2.7896 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.71067\n",
      "Epoch 220/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9988 - val_loss: 2.7877 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.71067\n",
      "Epoch 221/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9984 - val_loss: 2.7900 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.71067\n",
      "Epoch 222/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0016 - acc: 0.9993 - val_loss: 2.7918 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.71067\n",
      "Epoch 223/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9990 - val_loss: 2.7927 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00223: val_acc did not improve from 0.71067\n",
      "Epoch 224/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0016 - acc: 0.9990 - val_loss: 2.7945 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.71067\n",
      "Epoch 225/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0016 - acc: 0.9991 - val_loss: 2.7956 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.71067\n",
      "Epoch 226/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0015 - acc: 0.9992 - val_loss: 2.7954 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00226: val_acc did not improve from 0.71067\n",
      "Epoch 227/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9988 - val_loss: 2.7915 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.71067\n",
      "Epoch 228/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9987 - val_loss: 2.7918 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.71067\n",
      "Epoch 229/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0016 - acc: 0.9991 - val_loss: 2.7931 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.71067\n",
      "Epoch 230/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9988 - val_loss: 2.7877 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.71067\n",
      "Epoch 231/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9986 - val_loss: 2.7876 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.71067\n",
      "Epoch 232/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 2.7914 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00232: val_acc did not improve from 0.71067\n",
      "Epoch 233/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9988 - val_loss: 2.7920 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00233: val_acc did not improve from 0.71067\n",
      "Epoch 234/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0025 - acc: 0.9984 - val_loss: 2.7933 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00234: val_acc did not improve from 0.71067\n",
      "Epoch 235/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 2.7917 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00235: val_acc did not improve from 0.71067\n",
      "Epoch 236/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9990 - val_loss: 2.7935 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00236: val_acc did not improve from 0.71067\n",
      "Epoch 237/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 2.7934 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00237: val_acc did not improve from 0.71067\n",
      "Epoch 238/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0018 - acc: 0.9986 - val_loss: 2.7927 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00238: val_acc did not improve from 0.71067\n",
      "Epoch 239/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0021 - acc: 0.9984 - val_loss: 2.7888 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00239: val_acc did not improve from 0.71067\n",
      "Epoch 240/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0019 - acc: 0.9989 - val_loss: 2.7862 - val_acc: 0.6931\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00240: val_acc did not improve from 0.71067\n",
      "Epoch 241/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0016 - acc: 0.9992 - val_loss: 2.7870 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00241: val_acc did not improve from 0.71067\n",
      "Epoch 242/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 2.7906 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00242: val_acc did not improve from 0.71067\n",
      "Epoch 243/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9989 - val_loss: 2.7907 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00243: val_acc did not improve from 0.71067\n",
      "Epoch 244/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9988 - val_loss: 2.7916 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00244: val_acc did not improve from 0.71067\n",
      "Epoch 245/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0022 - acc: 0.9987 - val_loss: 2.7946 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00245: val_acc did not improve from 0.71067\n",
      "Epoch 246/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0023 - acc: 0.9988 - val_loss: 2.7954 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00246: val_acc did not improve from 0.71067\n",
      "Epoch 247/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0015 - acc: 0.9993 - val_loss: 2.7918 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00247: val_acc did not improve from 0.71067\n",
      "Epoch 248/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0025 - acc: 0.9986 - val_loss: 2.7939 - val_acc: 0.6909\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00248: val_acc did not improve from 0.71067\n",
      "Epoch 249/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0029 - acc: 0.9980 - val_loss: 2.7927 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00249: val_acc did not improve from 0.71067\n",
      "Epoch 250/250\n",
      "568/568 [==============================] - 67s 118ms/step - loss: 0.0020 - acc: 0.9990 - val_loss: 2.7932 - val_acc: 0.6920\n",
      "current decayed lr: 0.0000000\n",
      "\n",
      "Epoch 00250: val_acc did not improve from 0.71067\n"
     ]
    }
   ],
   "source": [
    "class printLR(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_decayed_lr = self.model.optimizer._decayed_lr(tf.float32).numpy()\n",
    "        print(\"current decayed lr: {:0.7f}\".format(current_decayed_lr))\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "initial_learning_rate = 1e-3\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                                                initial_learning_rate,\n",
    "                                                decay_steps = 100,\n",
    "                                                decay_rate = 0.96,\n",
    "                                                staircase = False)\n",
    "\n",
    "ckpt_modelpath = \"./full_aug.h5\"\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=ckpt_modelpath,\n",
    "    monitor='val_acc',\n",
    "    verbose=2,\n",
    "    save_best_only=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule),\n",
    "             metrics =['acc'])\n",
    "\n",
    "history = model.fit(train_generator, \n",
    "                   steps_per_epoch = len(train_generator),\n",
    "                   epochs = 100,\n",
    "                   validation_data = val_generator,\n",
    "                   validation_steps = len(val_generator),\n",
    "                   callbacks = [printLR(), checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8cfd988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MobilenetV3small\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_1 (Rescaling)         (None, 224, 224, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv (Conv2D)                   (None, 112, 112, 16) 432         rescaling_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv/BatchNorm (BatchNormalizat (None, 112, 112, 16) 64          Conv[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_28 (TFOpLa (None, 112, 112, 16) 0           Conv/BatchNorm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, 112, 112, 16) 0           tf.__operators__.add_28[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_28 (TFOpLambda (None, 112, 112, 16) 0           re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 112, 112, 16) 0           tf.math.multiply_28[0][0]        \n",
      "                                                                 Conv/BatchNorm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/depthwise/pad (Ze (None, 113, 113, 16) 0           multiply_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/depthwise (Depthw (None, 56, 56, 16)   144         expanded_conv/depthwise/pad[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/depthwise/BatchNo (None, 56, 56, 16)   64          expanded_conv/depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_34 (ReLU)                 (None, 56, 56, 16)   0           expanded_conv/depthwise/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/squeeze_excite/Av (None, 16)           0           re_lu_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 1, 1, 16)     0           expanded_conv/squeeze_excite/AvgP\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/squeeze_excite/Co (None, 1, 1, 8)      136         reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/squeeze_excite/Re (None, 1, 1, 8)      0           expanded_conv/squeeze_excite/Conv\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/squeeze_excite/Co (None, 1, 1, 16)     144         expanded_conv/squeeze_excite/Relu\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_29 (TFOpLa (None, 1, 1, 16)     0           expanded_conv/squeeze_excite/Conv\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_35 (ReLU)                 (None, 1, 1, 16)     0           tf.__operators__.add_29[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_29 (TFOpLambda (None, 1, 1, 16)     0           re_lu_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/squeeze_excite/Mu (None, 56, 56, 16)   0           re_lu_34[0][0]                   \n",
      "                                                                 tf.math.multiply_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/project (Conv2D)  (None, 56, 56, 16)   256         expanded_conv/squeeze_excite/Mul[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv/project/BatchNorm (None, 56, 56, 16)   64          expanded_conv/project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_1/expand (Conv2D) (None, 56, 56, 72)   1152        expanded_conv/project/BatchNorm[0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_1/expand/BatchNor (None, 56, 56, 72)   288         expanded_conv_1/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_36 (ReLU)                 (None, 56, 56, 72)   0           expanded_conv_1/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_1/depthwise/pad ( (None, 57, 57, 72)   0           re_lu_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_1/depthwise (Dept (None, 28, 28, 72)   648         expanded_conv_1/depthwise/pad[0][\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_1/depthwise/Batch (None, 28, 28, 72)   288         expanded_conv_1/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_37 (ReLU)                 (None, 28, 28, 72)   0           expanded_conv_1/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_1/project (Conv2D (None, 28, 28, 24)   1728        re_lu_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_1/project/BatchNo (None, 28, 28, 24)   96          expanded_conv_1/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_2/expand (Conv2D) (None, 28, 28, 88)   2112        expanded_conv_1/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_2/expand/BatchNor (None, 28, 28, 88)   352         expanded_conv_2/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_38 (ReLU)                 (None, 28, 28, 88)   0           expanded_conv_2/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_2/depthwise (Dept (None, 28, 28, 88)   792         re_lu_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_2/depthwise/Batch (None, 28, 28, 88)   352         expanded_conv_2/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_39 (ReLU)                 (None, 28, 28, 88)   0           expanded_conv_2/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_2/project (Conv2D (None, 28, 28, 24)   2112        re_lu_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_2/project/BatchNo (None, 28, 28, 24)   96          expanded_conv_2/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_2/Add (Add)       (None, 28, 28, 24)   0           expanded_conv_1/project/BatchNorm\n",
      "                                                                 expanded_conv_2/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/expand (Conv2D) (None, 28, 28, 96)   2304        expanded_conv_2/Add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/expand/BatchNor (None, 28, 28, 96)   384         expanded_conv_3/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_30 (TFOpLa (None, 28, 28, 96)   0           expanded_conv_3/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_40 (ReLU)                 (None, 28, 28, 96)   0           tf.__operators__.add_30[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_30 (TFOpLambda (None, 28, 28, 96)   0           re_lu_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 28, 28, 96)   0           tf.math.multiply_30[0][0]        \n",
      "                                                                 expanded_conv_3/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/depthwise/pad ( (None, 31, 31, 96)   0           multiply_20[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/depthwise (Dept (None, 14, 14, 96)   2400        expanded_conv_3/depthwise/pad[0][\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/depthwise/Batch (None, 14, 14, 96)   384         expanded_conv_3/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_31 (TFOpLa (None, 14, 14, 96)   0           expanded_conv_3/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_41 (ReLU)                 (None, 14, 14, 96)   0           tf.__operators__.add_31[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_31 (TFOpLambda (None, 14, 14, 96)   0           re_lu_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_21 (Multiply)          (None, 14, 14, 96)   0           tf.math.multiply_31[0][0]        \n",
      "                                                                 expanded_conv_3/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/squeeze_excite/ (None, 96)           0           multiply_21[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1, 1, 96)     0           expanded_conv_3/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/squeeze_excite/ (None, 1, 1, 24)     2328        reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/squeeze_excite/ (None, 1, 1, 24)     0           expanded_conv_3/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/squeeze_excite/ (None, 1, 1, 96)     2400        expanded_conv_3/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_32 (TFOpLa (None, 1, 1, 96)     0           expanded_conv_3/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_42 (ReLU)                 (None, 1, 1, 96)     0           tf.__operators__.add_32[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_32 (TFOpLambda (None, 1, 1, 96)     0           re_lu_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/squeeze_excite/ (None, 14, 14, 96)   0           multiply_21[0][0]                \n",
      "                                                                 tf.math.multiply_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/project (Conv2D (None, 14, 14, 40)   3840        expanded_conv_3/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/project/BatchNo (None, 14, 14, 40)   160         expanded_conv_3/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/expand (Conv2D) (None, 14, 14, 240)  9600        expanded_conv_3/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/expand/BatchNor (None, 14, 14, 240)  960         expanded_conv_4/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_33 (TFOpLa (None, 14, 14, 240)  0           expanded_conv_4/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_43 (ReLU)                 (None, 14, 14, 240)  0           tf.__operators__.add_33[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_33 (TFOpLambda (None, 14, 14, 240)  0           re_lu_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_22 (Multiply)          (None, 14, 14, 240)  0           tf.math.multiply_33[0][0]        \n",
      "                                                                 expanded_conv_4/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/depthwise (Dept (None, 14, 14, 240)  6000        multiply_22[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/depthwise/Batch (None, 14, 14, 240)  960         expanded_conv_4/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_34 (TFOpLa (None, 14, 14, 240)  0           expanded_conv_4/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_44 (ReLU)                 (None, 14, 14, 240)  0           tf.__operators__.add_34[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_34 (TFOpLambda (None, 14, 14, 240)  0           re_lu_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_23 (Multiply)          (None, 14, 14, 240)  0           tf.math.multiply_34[0][0]        \n",
      "                                                                 expanded_conv_4/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/squeeze_excite/ (None, 240)          0           multiply_23[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 1, 1, 240)    0           expanded_conv_4/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/squeeze_excite/ (None, 1, 1, 64)     15424       reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/squeeze_excite/ (None, 1, 1, 64)     0           expanded_conv_4/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/squeeze_excite/ (None, 1, 1, 240)    15600       expanded_conv_4/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_35 (TFOpLa (None, 1, 1, 240)    0           expanded_conv_4/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_45 (ReLU)                 (None, 1, 1, 240)    0           tf.__operators__.add_35[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_35 (TFOpLambda (None, 1, 1, 240)    0           re_lu_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/squeeze_excite/ (None, 14, 14, 240)  0           multiply_23[0][0]                \n",
      "                                                                 tf.math.multiply_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/project (Conv2D (None, 14, 14, 40)   9600        expanded_conv_4/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/project/BatchNo (None, 14, 14, 40)   160         expanded_conv_4/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/Add (Add)       (None, 14, 14, 40)   0           expanded_conv_3/project/BatchNorm\n",
      "                                                                 expanded_conv_4/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/expand (Conv2D) (None, 14, 14, 240)  9600        expanded_conv_4/Add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/expand/BatchNor (None, 14, 14, 240)  960         expanded_conv_5/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_36 (TFOpLa (None, 14, 14, 240)  0           expanded_conv_5/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_46 (ReLU)                 (None, 14, 14, 240)  0           tf.__operators__.add_36[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_36 (TFOpLambda (None, 14, 14, 240)  0           re_lu_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 14, 14, 240)  0           tf.math.multiply_36[0][0]        \n",
      "                                                                 expanded_conv_5/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/depthwise (Dept (None, 14, 14, 240)  6000        multiply_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/depthwise/Batch (None, 14, 14, 240)  960         expanded_conv_5/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_37 (TFOpLa (None, 14, 14, 240)  0           expanded_conv_5/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_47 (ReLU)                 (None, 14, 14, 240)  0           tf.__operators__.add_37[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_37 (TFOpLambda (None, 14, 14, 240)  0           re_lu_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 14, 14, 240)  0           tf.math.multiply_37[0][0]        \n",
      "                                                                 expanded_conv_5/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/squeeze_excite/ (None, 240)          0           multiply_25[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 1, 1, 240)    0           expanded_conv_5/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/squeeze_excite/ (None, 1, 1, 64)     15424       reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/squeeze_excite/ (None, 1, 1, 64)     0           expanded_conv_5/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/squeeze_excite/ (None, 1, 1, 240)    15600       expanded_conv_5/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_38 (TFOpLa (None, 1, 1, 240)    0           expanded_conv_5/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_48 (ReLU)                 (None, 1, 1, 240)    0           tf.__operators__.add_38[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_38 (TFOpLambda (None, 1, 1, 240)    0           re_lu_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/squeeze_excite/ (None, 14, 14, 240)  0           multiply_25[0][0]                \n",
      "                                                                 tf.math.multiply_38[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/project (Conv2D (None, 14, 14, 40)   9600        expanded_conv_5/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/project/BatchNo (None, 14, 14, 40)   160         expanded_conv_5/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/Add (Add)       (None, 14, 14, 40)   0           expanded_conv_4/Add[0][0]        \n",
      "                                                                 expanded_conv_5/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/expand (Conv2D) (None, 14, 14, 120)  4800        expanded_conv_5/Add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/expand/BatchNor (None, 14, 14, 120)  480         expanded_conv_6/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_39 (TFOpLa (None, 14, 14, 120)  0           expanded_conv_6/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_49 (ReLU)                 (None, 14, 14, 120)  0           tf.__operators__.add_39[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_39 (TFOpLambda (None, 14, 14, 120)  0           re_lu_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_26 (Multiply)          (None, 14, 14, 120)  0           tf.math.multiply_39[0][0]        \n",
      "                                                                 expanded_conv_6/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/depthwise (Dept (None, 14, 14, 120)  3000        multiply_26[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/depthwise/Batch (None, 14, 14, 120)  480         expanded_conv_6/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_40 (TFOpLa (None, 14, 14, 120)  0           expanded_conv_6/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_50 (ReLU)                 (None, 14, 14, 120)  0           tf.__operators__.add_40[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_40 (TFOpLambda (None, 14, 14, 120)  0           re_lu_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_27 (Multiply)          (None, 14, 14, 120)  0           tf.math.multiply_40[0][0]        \n",
      "                                                                 expanded_conv_6/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/squeeze_excite/ (None, 120)          0           multiply_27[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 1, 1, 120)    0           expanded_conv_6/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/squeeze_excite/ (None, 1, 1, 32)     3872        reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/squeeze_excite/ (None, 1, 1, 32)     0           expanded_conv_6/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/squeeze_excite/ (None, 1, 1, 120)    3960        expanded_conv_6/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_41 (TFOpLa (None, 1, 1, 120)    0           expanded_conv_6/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_51 (ReLU)                 (None, 1, 1, 120)    0           tf.__operators__.add_41[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_41 (TFOpLambda (None, 1, 1, 120)    0           re_lu_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/squeeze_excite/ (None, 14, 14, 120)  0           multiply_27[0][0]                \n",
      "                                                                 tf.math.multiply_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/project (Conv2D (None, 14, 14, 48)   5760        expanded_conv_6/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/project/BatchNo (None, 14, 14, 48)   192         expanded_conv_6/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/expand (Conv2D) (None, 14, 14, 144)  6912        expanded_conv_6/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/expand/BatchNor (None, 14, 14, 144)  576         expanded_conv_7/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_42 (TFOpLa (None, 14, 14, 144)  0           expanded_conv_7/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_52 (ReLU)                 (None, 14, 14, 144)  0           tf.__operators__.add_42[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_42 (TFOpLambda (None, 14, 14, 144)  0           re_lu_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_28 (Multiply)          (None, 14, 14, 144)  0           tf.math.multiply_42[0][0]        \n",
      "                                                                 expanded_conv_7/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/depthwise (Dept (None, 14, 14, 144)  3600        multiply_28[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/depthwise/Batch (None, 14, 14, 144)  576         expanded_conv_7/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_43 (TFOpLa (None, 14, 14, 144)  0           expanded_conv_7/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_53 (ReLU)                 (None, 14, 14, 144)  0           tf.__operators__.add_43[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_43 (TFOpLambda (None, 14, 14, 144)  0           re_lu_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_29 (Multiply)          (None, 14, 14, 144)  0           tf.math.multiply_43[0][0]        \n",
      "                                                                 expanded_conv_7/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/squeeze_excite/ (None, 144)          0           multiply_29[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 1, 1, 144)    0           expanded_conv_7/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/squeeze_excite/ (None, 1, 1, 40)     5800        reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/squeeze_excite/ (None, 1, 1, 40)     0           expanded_conv_7/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/squeeze_excite/ (None, 1, 1, 144)    5904        expanded_conv_7/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_44 (TFOpLa (None, 1, 1, 144)    0           expanded_conv_7/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_54 (ReLU)                 (None, 1, 1, 144)    0           tf.__operators__.add_44[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_44 (TFOpLambda (None, 1, 1, 144)    0           re_lu_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/squeeze_excite/ (None, 14, 14, 144)  0           multiply_29[0][0]                \n",
      "                                                                 tf.math.multiply_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/project (Conv2D (None, 14, 14, 48)   6912        expanded_conv_7/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/project/BatchNo (None, 14, 14, 48)   192         expanded_conv_7/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/Add (Add)       (None, 14, 14, 48)   0           expanded_conv_6/project/BatchNorm\n",
      "                                                                 expanded_conv_7/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/expand (Conv2D) (None, 14, 14, 288)  13824       expanded_conv_7/Add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/expand/BatchNor (None, 14, 14, 288)  1152        expanded_conv_8/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_45 (TFOpLa (None, 14, 14, 288)  0           expanded_conv_8/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_55 (ReLU)                 (None, 14, 14, 288)  0           tf.__operators__.add_45[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_45 (TFOpLambda (None, 14, 14, 288)  0           re_lu_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_30 (Multiply)          (None, 14, 14, 288)  0           tf.math.multiply_45[0][0]        \n",
      "                                                                 expanded_conv_8/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/depthwise/pad ( (None, 17, 17, 288)  0           multiply_30[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/depthwise (Dept (None, 7, 7, 288)    7200        expanded_conv_8/depthwise/pad[0][\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/depthwise/Batch (None, 7, 7, 288)    1152        expanded_conv_8/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_46 (TFOpLa (None, 7, 7, 288)    0           expanded_conv_8/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_56 (ReLU)                 (None, 7, 7, 288)    0           tf.__operators__.add_46[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_46 (TFOpLambda (None, 7, 7, 288)    0           re_lu_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_31 (Multiply)          (None, 7, 7, 288)    0           tf.math.multiply_46[0][0]        \n",
      "                                                                 expanded_conv_8/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/squeeze_excite/ (None, 288)          0           multiply_31[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 1, 1, 288)    0           expanded_conv_8/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/squeeze_excite/ (None, 1, 1, 72)     20808       reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/squeeze_excite/ (None, 1, 1, 72)     0           expanded_conv_8/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/squeeze_excite/ (None, 1, 1, 288)    21024       expanded_conv_8/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_47 (TFOpLa (None, 1, 1, 288)    0           expanded_conv_8/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_57 (ReLU)                 (None, 1, 1, 288)    0           tf.__operators__.add_47[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_47 (TFOpLambda (None, 1, 1, 288)    0           re_lu_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/squeeze_excite/ (None, 7, 7, 288)    0           multiply_31[0][0]                \n",
      "                                                                 tf.math.multiply_47[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/project (Conv2D (None, 7, 7, 96)     27648       expanded_conv_8/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/project/BatchNo (None, 7, 7, 96)     384         expanded_conv_8/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/expand (Conv2D) (None, 7, 7, 576)    55296       expanded_conv_8/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/expand/BatchNor (None, 7, 7, 576)    2304        expanded_conv_9/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_48 (TFOpLa (None, 7, 7, 576)    0           expanded_conv_9/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_58 (ReLU)                 (None, 7, 7, 576)    0           tf.__operators__.add_48[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_48 (TFOpLambda (None, 7, 7, 576)    0           re_lu_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 7, 7, 576)    0           tf.math.multiply_48[0][0]        \n",
      "                                                                 expanded_conv_9/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/depthwise (Dept (None, 7, 7, 576)    14400       multiply_32[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/depthwise/Batch (None, 7, 7, 576)    2304        expanded_conv_9/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_49 (TFOpLa (None, 7, 7, 576)    0           expanded_conv_9/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_59 (ReLU)                 (None, 7, 7, 576)    0           tf.__operators__.add_49[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_49 (TFOpLambda (None, 7, 7, 576)    0           re_lu_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 7, 7, 576)    0           tf.math.multiply_49[0][0]        \n",
      "                                                                 expanded_conv_9/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/squeeze_excite/ (None, 576)          0           multiply_33[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 1, 1, 576)    0           expanded_conv_9/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/squeeze_excite/ (None, 1, 1, 144)    83088       reshape_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/squeeze_excite/ (None, 1, 1, 144)    0           expanded_conv_9/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/squeeze_excite/ (None, 1, 1, 576)    83520       expanded_conv_9/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_50 (TFOpLa (None, 1, 1, 576)    0           expanded_conv_9/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_60 (ReLU)                 (None, 1, 1, 576)    0           tf.__operators__.add_50[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_50 (TFOpLambda (None, 1, 1, 576)    0           re_lu_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/squeeze_excite/ (None, 7, 7, 576)    0           multiply_33[0][0]                \n",
      "                                                                 tf.math.multiply_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/project (Conv2D (None, 7, 7, 96)     55296       expanded_conv_9/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/project/BatchNo (None, 7, 7, 96)     384         expanded_conv_9/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/Add (Add)       (None, 7, 7, 96)     0           expanded_conv_8/project/BatchNorm\n",
      "                                                                 expanded_conv_9/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/expand (Conv2D (None, 7, 7, 576)    55296       expanded_conv_9/Add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/expand/BatchNo (None, 7, 7, 576)    2304        expanded_conv_10/expand[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_51 (TFOpLa (None, 7, 7, 576)    0           expanded_conv_10/expand/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_61 (ReLU)                 (None, 7, 7, 576)    0           tf.__operators__.add_51[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_51 (TFOpLambda (None, 7, 7, 576)    0           re_lu_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 7, 7, 576)    0           tf.math.multiply_51[0][0]        \n",
      "                                                                 expanded_conv_10/expand/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/depthwise (Dep (None, 7, 7, 576)    14400       multiply_34[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/depthwise/Batc (None, 7, 7, 576)    2304        expanded_conv_10/depthwise[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_52 (TFOpLa (None, 7, 7, 576)    0           expanded_conv_10/depthwise/BatchN\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_62 (ReLU)                 (None, 7, 7, 576)    0           tf.__operators__.add_52[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_52 (TFOpLambda (None, 7, 7, 576)    0           re_lu_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 7, 7, 576)    0           tf.math.multiply_52[0][0]        \n",
      "                                                                 expanded_conv_10/depthwise/BatchN\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/squeeze_excite (None, 576)          0           multiply_35[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 1, 1, 576)    0           expanded_conv_10/squeeze_excite/A\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/squeeze_excite (None, 1, 1, 144)    83088       reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/squeeze_excite (None, 1, 1, 144)    0           expanded_conv_10/squeeze_excite/C\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/squeeze_excite (None, 1, 1, 576)    83520       expanded_conv_10/squeeze_excite/R\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_53 (TFOpLa (None, 1, 1, 576)    0           expanded_conv_10/squeeze_excite/C\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_63 (ReLU)                 (None, 1, 1, 576)    0           tf.__operators__.add_53[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_53 (TFOpLambda (None, 1, 1, 576)    0           re_lu_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/squeeze_excite (None, 7, 7, 576)    0           multiply_35[0][0]                \n",
      "                                                                 tf.math.multiply_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/project (Conv2 (None, 7, 7, 96)     55296       expanded_conv_10/squeeze_excite/M\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/project/BatchN (None, 7, 7, 96)     384         expanded_conv_10/project[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/Add (Add)      (None, 7, 7, 96)     0           expanded_conv_9/Add[0][0]        \n",
      "                                                                 expanded_conv_10/project/BatchNor\n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 576)    55296       expanded_conv_10/Add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1/BatchNorm (BatchNormaliz (None, 7, 7, 576)    2304        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_54 (TFOpLa (None, 7, 7, 576)    0           Conv_1/BatchNorm[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_64 (ReLU)                 (None, 7, 7, 576)    0           tf.__operators__.add_54[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_54 (TFOpLambda (None, 7, 7, 576)    0           re_lu_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_36 (Multiply)          (None, 7, 7, 576)    0           tf.math.multiply_54[0][0]        \n",
      "                                                                 Conv_1/BatchNorm[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_2 (Conv2D)                 (None, 7, 7, 1024)   590848      multiply_36[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_55 (TFOpLa (None, 7, 7, 1024)   0           Conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_65 (ReLU)                 (None, 7, 7, 1024)   0           tf.__operators__.add_55[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_55 (TFOpLambda (None, 7, 7, 1024)   0           re_lu_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_37 (Multiply)          (None, 7, 7, 1024)   0           tf.math.multiply_55[0][0]        \n",
      "                                                                 Conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1024)         0           multiply_37[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,529,968\n",
      "Trainable params: 1,517,856\n",
      "Non-trainable params: 12,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.layers[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "648dd367",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('C:\\\\Users\\\\SDH-LAB\\\\Desktop\\\\SMARCLE_MAKERS_DAY\\\\acc_07099.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b49eec42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[103 167  38]\n",
      " [112 155  34]\n",
      " [105 149  46]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report,confusion_matrix, ConfusionMatrixDisplay, top_k_accuracy_score\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Y_pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "target_names = test_generator.class_indices.keys()\n",
    "print('Confusion Matrix')\n",
    "con_mat = confusion_matrix(test_generator.classes, y_pred)\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "print(con_mat)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                         index = target_names,\n",
    "                         columns = target_names)\n",
    "figure = plt.figure(figsize = (8,8))\n",
    "sns.heatmap(con_mat_df, annot=True, cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43dad5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[106 168  34]\n",
      " [114 150  37]\n",
      " [100 153  47]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loaded_model -> confusion matrix\n",
    "Y_pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "target_names = test_generator.class_indices.keys()\n",
    "print('Confusion Matrix')\n",
    "con_mat = confusion_matrix(test_generator.classes, y_pred)\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "print(con_mat)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                         index = target_names,\n",
    "                         columns = target_names)\n",
    "figure = plt.figure(figsize = (8,8))\n",
    "sns.heatmap(con_mat_df, annot=True, cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b92befd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      blouse       0.32      0.33      0.33       308\n",
      "      hoodie       0.33      0.51      0.40       301\n",
      "     t_shirt       0.39      0.15      0.22       300\n",
      "\n",
      "    accuracy                           0.33       909\n",
      "   macro avg       0.35      0.33      0.32       909\n",
      "weighted avg       0.35      0.33      0.32       909\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# acc, f1-score . etc\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175e3c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.text_label = QLabel(self)\n",
    "        self.text_label.move(150, 350)\n",
    "        self.text_label.setText('Check it out!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba916325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf42e13e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_nightly",
   "language": "python",
   "name": "tf_nightly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
